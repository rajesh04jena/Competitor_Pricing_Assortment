{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bcd302a7-7e11-4e82-97d9-38140e96711f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from datetime import date, datetime\n",
    "import numpy as np\n",
    "import random\n",
    "import decimal\n",
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dd4604b8-6790-412a-ae14-4d2b381c3277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config : Provide Category to extract and pagination\n",
    "amazon_listing_url = pd.DataFrame({ 'category' : ['Air Conditioner'] , 'url' : ['https://www.amazon.in/s?rh=n%3A3474656031&fs=true'] }) \n",
    "total_pages = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2d332d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Price, Ratings and Technical Spec Details Scraping functions\n",
    "\n",
    "def init_browser():\n",
    "    \"\"\"Initialize and return a configured Chrome browser instance\"\"\"\n",
    "    options = ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--incognito\")\n",
    "    options.add_argument(\"start-maximized\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    return Chrome(options=options)\n",
    "\n",
    "def delete_cache(driver):\n",
    "    driver.execute_script(\"window.open('')\")  # Create a separate tab than the main one\n",
    "    driver.switch_to.window(driver.window_handles[-1])  # Switch window to the second tab\n",
    "    #driver.get('chrome://settings/clearBrowserData')  # Open your chrome settings.\n",
    "    #driver.findElement(By.xpath(\"//*[@id='clearBrowsingDataConfirm']\")).click()\n",
    "    driver.execute_cdp_cmd(\"Network.clearBrowserCache\", {})\n",
    "   #perform_actions(driver, Keys.TAB * 2 + Keys.DOWN * 4 + Keys.TAB * 5 + Keys.ENTER)  # Tab to the time select and key down to say \"All Time\" then go to the Confirm button and press Enter\n",
    "    driver.close()  # Close that window\n",
    "    driver.switch_to.window(driver.window_handles[0])  # Switch Selenium controls to the original tab to continue normal functionality.\n",
    "\n",
    "def perform_actions(driver, keys):\n",
    "    actions = ActionChains(driver)\n",
    "    actions.send_keys(keys)\n",
    "    time.sleep(1)\n",
    "    print('Performing Actions!')\n",
    "    actions.perform()\n",
    "\n",
    "# ASIN Scraping functions\n",
    "def scrape_asin_urls(amazon_listing_url, total_pages):\n",
    "    \"\"\"Main function to scrape ASINs from listing pages\"\"\"\n",
    "    final_collated_urls = pd.DataFrame()\n",
    "    pages = total_pages\n",
    "    for base_url in amazon_listing_url:\n",
    "        all_product_urls = process_base_url(base_url, pages)\n",
    "        final_collated_urls = pd.concat([final_collated_urls, all_product_urls])\n",
    "        final_collated_urls = final_collated_urls.drop_duplicates('asin')\n",
    "    \n",
    "    final_collated_urls['Product URL'] = 'https://www.amazon.in/dp/' + final_collated_urls['asin'].astype(str)\n",
    "    return final_collated_urls\n",
    "\n",
    "def process_base_url(base_url, total_pages):\n",
    "    \"\"\"Process all pages for a single base URL\"\"\"\n",
    "    all_product_urls = pd.DataFrame()\n",
    "    \n",
    "    for page in range(1, total_pages + 1):\n",
    "        url = base_url + \"&page=\" + str(page)          \n",
    "        print(url)\n",
    "        browser = init_browser()\n",
    "        browser.get(url)\n",
    "        html = browser.page_source\n",
    "        delete_cache(browser)\n",
    "        browser.quit()\n",
    "        time.sleep(random.uniform(0.2, 0.8))\n",
    "        \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        page_asin_df = extract_asin_from_page(soup)\n",
    "        page_asin_df['listing_url'] = base_url\n",
    "        all_product_urls = pd.concat([all_product_urls, page_asin_df])\n",
    "    \n",
    "    return all_product_urls.reset_index(drop=True)\n",
    "\n",
    "def extract_asin_from_page(soup):\n",
    "    \"\"\"Extract ASINs from a single page\"\"\"\n",
    "    product_urls = []\n",
    "    for div in soup.find_all(\"div\"):\n",
    "        if (data_asin := div.get(\"data-asin\")) and (data_index := div.get(\"data-index\")):\n",
    "            product_urls.append({'asin': data_asin, 'product default order number': data_index})\n",
    "    return pd.DataFrame(product_urls)\n",
    "\n",
    "# Product Detail Scraping functions\n",
    "def scrape_product_details(final_collated_urls):\n",
    "    \"\"\"Main function to scrape product details from product pages\"\"\"\n",
    "    final_scrapped_df = pd.DataFrame()\n",
    "    \n",
    "    for product_url in final_collated_urls['Product URL'].tolist():\n",
    "        product_df = scrape_single_product(product_url)\n",
    "        product_df['Retailer'] = 'Amazon'\n",
    "        final_scrapped_df = pd.concat([final_scrapped_df, product_df])\n",
    "    \n",
    "    return final_scrapped_df\n",
    "\n",
    "def scrape_single_product(product_url):\n",
    "    \"\"\"Scrape details from a single product page\"\"\"\n",
    "    product_df = pd.DataFrame({'Product URL': [product_url]})\n",
    "    try:\n",
    "        browser = init_browser()\n",
    "        browser.get(product_url)\n",
    "        html = browser.page_source\n",
    "        delete_cache(browser)\n",
    "        browser.quit()\n",
    "        time.sleep(random.uniform(0.5, 1.05))\n",
    "        \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        product_df = extract_basic_info(soup, product_df)\n",
    "        product_df = extract_pricing_info(soup, product_df)\n",
    "        product_df = extract_ratings_info(soup, product_df)\n",
    "        product_df = extract_additional_info(soup, product_df)\n",
    "        product_df = extract_technical_details(soup, product_df)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {product_url}: {str(e)}\")\n",
    "    \n",
    "    return product_df\n",
    "\n",
    "def extract_basic_info(soup, df):\n",
    "    \"\"\"Extract basic product information\"\"\"\n",
    "    try: df['Title'] = soup.find(\"span\", {'id': 'productTitle'}).text.strip()\n",
    "    except: df['Title'] = ''\n",
    "    \n",
    "    try: df['SKU Product'] = soup.find('input', {'id': 'ASIN'}).get('value')\n",
    "    except: df['SKU Product'] = ''\n",
    "    \n",
    "    df['Scraping Date'] = date.today()\n",
    "    df['Scraping Time'] = datetime.now()\n",
    "    return df\n",
    "\n",
    "def extract_pricing_info(soup, df):\n",
    "    \"\"\"Extract pricing-related information\"\"\"\n",
    "    try:\n",
    "        price = soup.find('span', {'class': 'a-price-whole'}).text.strip()\n",
    "        df['Selling Price'] = float(re.sub(r'[^\\d.]', '', price))\n",
    "    except: df['Selling Price'] = ''\n",
    "    \n",
    "    try:\n",
    "        mrp = soup.find(\"span\", class_=\"a-price a-text-price\").find(\"span\", class_=\"a-offscreen\").text\n",
    "        df['MRP'] = float(re.sub(r'[^\\d.]', '', mrp))\n",
    "    except: df['MRP'] = ''\n",
    "    \n",
    "    try: df['Discount'] = soup.find(\"span\", class_=\"a-size-large a-color-price\").text.strip().replace(\"-\", \"\")\n",
    "    except: df['Discount'] = ''\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_ratings_info(soup, df):\n",
    "    \"\"\"Extract rating-related information\"\"\"\n",
    "    try: df['no_ratings'] = soup.find(\"span\", {'id': 'acrCustomerReviewText'}).text.strip()\n",
    "    except: df['no_ratings'] = ''\n",
    "    \n",
    "    try: df['avg_rating'] = float(soup.find(\"span\", {'class': 'reviewCountTextLinkedHistogram'}).text.split()[0])\n",
    "    except: df['avg_rating'] = ''\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_additional_info(soup, df):\n",
    "    \"\"\"Extract additional product information\"\"\"\n",
    "    try: df['Stock Status'] = soup.find(\"div\", {'id': 'availabilityInsideBuyBox_feature_div'}).text.strip()\n",
    "    except: df['Stock Status'] = ''\n",
    "    \n",
    "    try: df['Seller'] = soup.find(\"a\", {'id': 'sellerProfileTriggerId'}).text.strip()\n",
    "    except: df['Seller'] = ''\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_technical_details(soup, df):\n",
    "    \"\"\"Extract technical details from product tables\"\"\"\n",
    "    try:\n",
    "        table = soup.find(\"div\", {\"id\": \"productOverview_feature_div\"}).find(\n",
    "            \"table\", class_=\"a-normal a-spacing-micro\"\n",
    "        )\n",
    "        data = []\n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            row = [td.text for td in tr.find_all(\"td\")]\n",
    "            data.append(row)\n",
    "\n",
    "        table_df = pd.DataFrame(data)\n",
    "        table_df = table_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "        table_df.columns = [\"Attribute_Name\", \"Attribute_Value\"]\n",
    "        table_df = table_df.reset_index(drop=True)\n",
    "        df = pd.concat([df, table_df], axis=1)\n",
    "        col_subset = list(set(df.columns.tolist()) - set([\"Attribute_Name\", \"Attribute_Value\"]))\n",
    "        df[col_subset] = df[col_subset].fillna(method=\"ffill\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting from productOverview_feature_div: {e}\")\n",
    "\n",
    "    try:\n",
    "        table = soup.find(\"table\", {\"id\": \"productDetails_detailBullets_sections1\"})\n",
    "        final_product_spec_df = pd.DataFrame()\n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            product_value = tr.find(\"td\").text.strip()\n",
    "            product_name = tr.find(\"th\").text.strip()\n",
    "            product_spec_df = pd.DataFrame(\n",
    "                {\"Attribute_Name\": [product_name], \"Attribute_Value\": [product_value]}\n",
    "            )\n",
    "            final_product_spec_df = pd.concat([final_product_spec_df, product_spec_df], ignore_index=True)\n",
    "        df = pd.concat([df, final_product_spec_df], ignore_index=True)\n",
    "        cols = df.drop(columns=[\"Attribute_Name\", \"Attribute_Value\"]).columns.tolist()\n",
    "        df[cols] = df[cols].fillna(method=\"ffill\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting from productDetails_detailBullets_sections1: {e}\")\n",
    "\n",
    "    try:\n",
    "        table = soup.find(\"table\", {\"id\": \"productDetails_techSpec_section_1\"})\n",
    "        final_product_spec_df = pd.DataFrame()\n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            product_value = tr.find(\"td\").text.strip()\n",
    "            product_name = tr.find(\"th\").text.strip()\n",
    "            product_spec_df = pd.DataFrame(\n",
    "                {\"Attribute_Name\": [product_name], \"Attribute_Value\": [product_value]}\n",
    "            )\n",
    "            final_product_spec_df = pd.concat([final_product_spec_df, product_spec_df], ignore_index=True)\n",
    "        df = pd.concat([df, final_product_spec_df], ignore_index=True)\n",
    "        cols = df.drop(columns=[\"Attribute_Name\", \"Attribute_Value\"]).columns.tolist()\n",
    "        df[cols] = df[cols].fillna(method=\"ffill\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting from productDetails_techSpec_section_1: {e}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "da022644-3a02-46a0-a411-455f584062ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.amazon.in/s?rh=n%3A3474656031&fs=true&page=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>product default order number</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>Product URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0BK1KS6ZD</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.amazon.in/s?rh=n%3A3474656031&amp;fs=true</td>\n",
       "      <td>https://www.amazon.in/dp/B0BK1KS6ZD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0DS2DX5ZP</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.amazon.in/s?rh=n%3A3474656031&amp;fs=true</td>\n",
       "      <td>https://www.amazon.in/dp/B0DS2DX5ZP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0DQQ4XDBB</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.amazon.in/s?rh=n%3A3474656031&amp;fs=true</td>\n",
       "      <td>https://www.amazon.in/dp/B0DQQ4XDBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0CWVDXYX1</td>\n",
       "      <td>6</td>\n",
       "      <td>https://www.amazon.in/s?rh=n%3A3474656031&amp;fs=true</td>\n",
       "      <td>https://www.amazon.in/dp/B0CWVDXYX1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0DRG7M72Z</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.amazon.in/s?rh=n%3A3474656031&amp;fs=true</td>\n",
       "      <td>https://www.amazon.in/dp/B0DRG7M72Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin product default order number  \\\n",
       "0  B0BK1KS6ZD                            2   \n",
       "1  B0DS2DX5ZP                            3   \n",
       "2  B0DQQ4XDBB                            4   \n",
       "3  B0CWVDXYX1                            6   \n",
       "4  B0DRG7M72Z                            7   \n",
       "\n",
       "                                         listing_url  \\\n",
       "0  https://www.amazon.in/s?rh=n%3A3474656031&fs=true   \n",
       "1  https://www.amazon.in/s?rh=n%3A3474656031&fs=true   \n",
       "2  https://www.amazon.in/s?rh=n%3A3474656031&fs=true   \n",
       "3  https://www.amazon.in/s?rh=n%3A3474656031&fs=true   \n",
       "4  https://www.amazon.in/s?rh=n%3A3474656031&fs=true   \n",
       "\n",
       "                           Product URL  \n",
       "0  https://www.amazon.in/dp/B0BK1KS6ZD  \n",
       "1  https://www.amazon.in/dp/B0DS2DX5ZP  \n",
       "2  https://www.amazon.in/dp/B0DQQ4XDBB  \n",
       "3  https://www.amazon.in/dp/B0CWVDXYX1  \n",
       "4  https://www.amazon.in/dp/B0DRG7M72Z  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ASIN Scraping\n",
    "amazon_listing_url = amazon_listing_url['url'].unique().tolist()\n",
    "final_collated_urls = scrape_asin_urls(amazon_listing_url, total_pages)\n",
    "#final_collated_urls.to_csv('product_urls_amazon.csv', index=False)\n",
    "final_collated_urls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e26c40cb-7d21-4939-addb-05730f3ee322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>SKU Product</th>\n",
       "      <th>Scraping Date</th>\n",
       "      <th>Scraping Time</th>\n",
       "      <th>Selling Price</th>\n",
       "      <th>MRP</th>\n",
       "      <th>Discount</th>\n",
       "      <th>no_ratings</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>Stock Status</th>\n",
       "      <th>Seller</th>\n",
       "      <th>Attribute_Name</th>\n",
       "      <th>Attribute_Value</th>\n",
       "      <th>Retailer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.amazon.in/dp/B0BK1KS6ZD</td>\n",
       "      <td>Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...</td>\n",
       "      <td>B0BK1KS6ZD</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>2025-03-01 14:41:12.825522</td>\n",
       "      <td>36990.0</td>\n",
       "      <td>58400.0</td>\n",
       "      <td></td>\n",
       "      <td>3,950 ratings</td>\n",
       "      <td>3.9</td>\n",
       "      <td>In stock</td>\n",
       "      <td>DAWNTECH ELECTRONICS PRIVATE LIMITED</td>\n",
       "      <td>Brand</td>\n",
       "      <td>Daikin</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.amazon.in/dp/B0BK1KS6ZD</td>\n",
       "      <td>Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...</td>\n",
       "      <td>B0BK1KS6ZD</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>2025-03-01 14:41:12.825522</td>\n",
       "      <td>36990.0</td>\n",
       "      <td>58400.0</td>\n",
       "      <td></td>\n",
       "      <td>3,950 ratings</td>\n",
       "      <td>3.9</td>\n",
       "      <td>In stock</td>\n",
       "      <td>DAWNTECH ELECTRONICS PRIVATE LIMITED</td>\n",
       "      <td>Capacity</td>\n",
       "      <td>1.5 Tons</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.amazon.in/dp/B0BK1KS6ZD</td>\n",
       "      <td>Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...</td>\n",
       "      <td>B0BK1KS6ZD</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>2025-03-01 14:41:12.825522</td>\n",
       "      <td>36990.0</td>\n",
       "      <td>58400.0</td>\n",
       "      <td></td>\n",
       "      <td>3,950 ratings</td>\n",
       "      <td>3.9</td>\n",
       "      <td>In stock</td>\n",
       "      <td>DAWNTECH ELECTRONICS PRIVATE LIMITED</td>\n",
       "      <td>Cooling Power</td>\n",
       "      <td>17100 British Thermal Units</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.amazon.in/dp/B0BK1KS6ZD</td>\n",
       "      <td>Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...</td>\n",
       "      <td>B0BK1KS6ZD</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>2025-03-01 14:41:12.825522</td>\n",
       "      <td>36990.0</td>\n",
       "      <td>58400.0</td>\n",
       "      <td></td>\n",
       "      <td>3,950 ratings</td>\n",
       "      <td>3.9</td>\n",
       "      <td>In stock</td>\n",
       "      <td>DAWNTECH ELECTRONICS PRIVATE LIMITED</td>\n",
       "      <td>Special Feature</td>\n",
       "      <td>High Ambient Operation upto 52°C, 3D Airflow, ...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.amazon.in/dp/B0BK1KS6ZD</td>\n",
       "      <td>Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...</td>\n",
       "      <td>B0BK1KS6ZD</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>2025-03-01 14:41:12.825522</td>\n",
       "      <td>36990.0</td>\n",
       "      <td>58400.0</td>\n",
       "      <td></td>\n",
       "      <td>3,950 ratings</td>\n",
       "      <td>3.9</td>\n",
       "      <td>In stock</td>\n",
       "      <td>DAWNTECH ELECTRONICS PRIVATE LIMITED</td>\n",
       "      <td>Product Dimensions</td>\n",
       "      <td>22.9D x 88.5W x 29.8H Centimeters</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Product URL  \\\n",
       "0  https://www.amazon.in/dp/B0BK1KS6ZD   \n",
       "1  https://www.amazon.in/dp/B0BK1KS6ZD   \n",
       "2  https://www.amazon.in/dp/B0BK1KS6ZD   \n",
       "3  https://www.amazon.in/dp/B0BK1KS6ZD   \n",
       "4  https://www.amazon.in/dp/B0BK1KS6ZD   \n",
       "\n",
       "                                               Title SKU Product  \\\n",
       "0  Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...  B0BK1KS6ZD   \n",
       "1  Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...  B0BK1KS6ZD   \n",
       "2  Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...  B0BK1KS6ZD   \n",
       "3  Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...  B0BK1KS6ZD   \n",
       "4  Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...  B0BK1KS6ZD   \n",
       "\n",
       "  Scraping Date              Scraping Time  Selling Price      MRP Discount  \\\n",
       "0    2025-03-01 2025-03-01 14:41:12.825522        36990.0  58400.0            \n",
       "1    2025-03-01 2025-03-01 14:41:12.825522        36990.0  58400.0            \n",
       "2    2025-03-01 2025-03-01 14:41:12.825522        36990.0  58400.0            \n",
       "3    2025-03-01 2025-03-01 14:41:12.825522        36990.0  58400.0            \n",
       "4    2025-03-01 2025-03-01 14:41:12.825522        36990.0  58400.0            \n",
       "\n",
       "      no_ratings  avg_rating Stock Status  \\\n",
       "0  3,950 ratings         3.9     In stock   \n",
       "1  3,950 ratings         3.9     In stock   \n",
       "2  3,950 ratings         3.9     In stock   \n",
       "3  3,950 ratings         3.9     In stock   \n",
       "4  3,950 ratings         3.9     In stock   \n",
       "\n",
       "                                 Seller      Attribute_Name  \\\n",
       "0  DAWNTECH ELECTRONICS PRIVATE LIMITED               Brand   \n",
       "1  DAWNTECH ELECTRONICS PRIVATE LIMITED            Capacity   \n",
       "2  DAWNTECH ELECTRONICS PRIVATE LIMITED       Cooling Power   \n",
       "3  DAWNTECH ELECTRONICS PRIVATE LIMITED     Special Feature   \n",
       "4  DAWNTECH ELECTRONICS PRIVATE LIMITED  Product Dimensions   \n",
       "\n",
       "                                     Attribute_Value Retailer  \n",
       "0                                             Daikin   Amazon  \n",
       "1                                           1.5 Tons   Amazon  \n",
       "2                        17100 British Thermal Units   Amazon  \n",
       "3  High Ambient Operation upto 52°C, 3D Airflow, ...   Amazon  \n",
       "4                  22.9D x 88.5W x 29.8H Centimeters   Amazon  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Product Detail Scraping\n",
    "final_scrapped_df = scrape_product_details(final_collated_urls)\n",
    "#final_scrapped_df.to_csv('amazon_scrapped_data.csv', index=False)\n",
    "final_scrapped_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
