{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "56b18e4d-a754-4000-9b61-cef2fa6b347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "from datetime import date, datetime\n",
    "import numpy as np\n",
    "import random\n",
    "import decimal\n",
    "from selenium.webdriver import Chrome, ChromeOptions\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import warnings\n",
    "import dask\n",
    "from dask import delayed\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3967450c-6f8c-4128-bd11-a989aa7efb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Initial Configuration (Keep as DataFrame) ---\n",
    "amazon_listing_df = pd.DataFrame({ \n",
    "    'category': ['Air Conditioner'], \n",
    "    'url': ['https://www.amazon.in/s?rh=n%3A3474656031&fs=true'] \n",
    "})\n",
    "total_pages = 1\n",
    "amazon_listing_url = amazon_listing_df['url'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "13290dbd-03ee-4c9f-b2f4-1248065269b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Price, Ratings and Technical Spec Details Scraping functions\n",
    "def init_browser():\n",
    "    \"\"\"Initialize and return a configured Chrome browser instance\"\"\"\n",
    "    options = ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--incognito\")\n",
    "    options.add_argument(\"start-maximized\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    return Chrome(options=options)\n",
    "\n",
    "def delete_cache(driver):\n",
    "    driver.execute_script(\"window.open('')\")  # Create a separate tab than the main one\n",
    "    driver.switch_to.window(driver.window_handles[-1])  # Switch window to the second tab\n",
    "    #driver.get('chrome://settings/clearBrowserData')  # Open your chrome settings.\n",
    "    #driver.findElement(By.xpath(\"//*[@id='clearBrowsingDataConfirm']\")).click()\n",
    "    driver.execute_cdp_cmd(\"Network.clearBrowserCache\", {})\n",
    "    perform_actions(driver, Keys.TAB * 2 + Keys.DOWN * 4 + Keys.TAB * 5 + Keys.ENTER)  # Tab to the time select and key down to say \"All Time\" then go to the Confirm button and press Enter\n",
    "    driver.close()  # Close that window\n",
    "    driver.switch_to.window(driver.window_handles[0])  # Switch Selenium controls to the original tab to continue normal functionality.\n",
    "\n",
    "def perform_actions(driver, keys):\n",
    "    actions = ActionChains(driver)\n",
    "    actions.send_keys(keys)\n",
    "    time.sleep(1)\n",
    "    print('Performing Actions!')\n",
    "    actions.perform()\n",
    "\n",
    "# ASIN Scraping functions \n",
    "def scrape_asin_urls(amazon_listing_url, total_pages):\n",
    "    \"\"\"Main function to scrape ASINs (parallelized at PAGE level)\"\"\"\n",
    "    # Generate all page URLs upfront\n",
    "    all_page_urls = []\n",
    "    for base_url in amazon_listing_url:\n",
    "        for page in range(1, total_pages + 1):\n",
    "            url = f\"{base_url}&page={page}\"\n",
    "            all_page_urls.append(url)\n",
    "    \n",
    "    # Process ALL pages in parallel (flat structure)\n",
    "    page_tasks = [delayed(process_page)(url) for url in all_page_urls]\n",
    "    all_page_dfs = dask.compute(*page_tasks)\n",
    "    \n",
    "    # Combine results\n",
    "    final_collated_urls = pd.concat(all_page_dfs)\n",
    "    final_collated_urls = final_collated_urls.drop_duplicates('asin')\n",
    "    final_collated_urls['Product URL'] = 'https://www.amazon.in/dp/' + final_collated_urls['asin'].astype(str)\n",
    "    return final_collated_urls\n",
    "\n",
    "def process_page(url):\n",
    "    \"\"\"Process a SINGLE page (now takes full URL)\"\"\"\n",
    "    print(url)\n",
    "    browser = init_browser()\n",
    "    browser.get(url)\n",
    "    html = browser.page_source\n",
    "    delete_cache(browser)\n",
    "    browser.quit()\n",
    "    time.sleep(random.uniform(0.2, 0.8))\n",
    "    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    page_asin_df = extract_asin_from_page(soup)\n",
    "    page_asin_df['listing_url'] = url.split(\"&page=\")[0]  # Extract base URL\n",
    "    return page_asin_df\n",
    "\n",
    "def process_base_url(base_url, total_pages):\n",
    "    \"\"\"Process all pages for a single base URL (parallelized)\"\"\"\n",
    "    # Parallelize pages\n",
    "    page_tasks = []\n",
    "    for page in range(1, total_pages + 1):\n",
    "        page_task = delayed(process_page)(base_url, page)\n",
    "        page_tasks.append(page_task)\n",
    "    \n",
    "    # Combine results\n",
    "    return delayed(pd.concat)(page_tasks)\n",
    "\n",
    "# Product Detail Scraping functions \n",
    "def scrape_product_details(final_collated_urls):\n",
    "    \"\"\"Parallelize product scraping\"\"\"\n",
    "    product_tasks = [delayed(scrape_single_product)(url) for url in final_collated_urls['Product URL'].tolist()]\n",
    "    product_dfs = dask.compute(*product_tasks)\n",
    "    final_scrapped_df = pd.concat(product_dfs)\n",
    "    final_scrapped_df['Retailer'] = 'Amazon'\n",
    "    return final_scrapped_df\n",
    "    \n",
    "def scrape_single_product(product_url):\n",
    "    \"\"\"Scrape details from a single product page\"\"\"\n",
    "    product_df = pd.DataFrame({'Product URL': [product_url]})\n",
    "    try:\n",
    "        browser = init_browser()\n",
    "        browser.get(product_url)\n",
    "        html = browser.page_source\n",
    "        delete_cache(browser)\n",
    "        browser.quit()\n",
    "        time.sleep(random.uniform(0.5, 1.05))\n",
    "        \n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        product_df = extract_basic_info(soup, product_df)\n",
    "        product_df = extract_pricing_info(soup, product_df)\n",
    "        product_df = extract_ratings_info(soup, product_df)\n",
    "        product_df = extract_additional_info(soup, product_df)\n",
    "        product_df = extract_technical_details(soup, product_df)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {product_url}: {str(e)}\")\n",
    "    \n",
    "    return product_df\n",
    "\n",
    "def extract_basic_info(soup, df):\n",
    "    \"\"\"Extract basic product information\"\"\"\n",
    "    try: df['Title'] = soup.find(\"span\", {'id': 'productTitle'}).text.strip()\n",
    "    except: df['Title'] = ''\n",
    "    \n",
    "    try: df['SKU Product'] = soup.find('input', {'id': 'ASIN'}).get('value')\n",
    "    except: df['SKU Product'] = ''\n",
    "    \n",
    "    df['Scraping Date'] = date.today()\n",
    "    df['Scraping Time'] = datetime.now()\n",
    "    return df\n",
    "\n",
    "def extract_pricing_info(soup, df):\n",
    "    \"\"\"Extract pricing-related information\"\"\"\n",
    "    try:\n",
    "        price = soup.find('span', {'class': 'a-price-whole'}).text.strip()\n",
    "        df['Selling Price'] = float(re.sub(r'[^\\d.]', '', price))\n",
    "    except: df['Selling Price'] = ''\n",
    "    \n",
    "    try:\n",
    "        mrp = soup.find(\"span\", class_=\"a-price a-text-price\").find(\"span\", class_=\"a-offscreen\").text\n",
    "        df['MRP'] = float(re.sub(r'[^\\d.]', '', mrp))\n",
    "    except: df['MRP'] = ''\n",
    "    \n",
    "    try: df['Discount'] = soup.find(\"span\", class_=\"a-size-large a-color-price\").text.strip().replace(\"-\", \"\")\n",
    "    except: df['Discount'] = ''\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_ratings_info(soup, df):\n",
    "    \"\"\"Extract rating-related information\"\"\"\n",
    "    try: df['no_ratings'] = soup.find(\"span\", {'id': 'acrCustomerReviewText'}).text.strip()\n",
    "    except: df['no_ratings'] = ''\n",
    "    \n",
    "    try: df['avg_rating'] = float(soup.find(\"span\", {'class': 'reviewCountTextLinkedHistogram'}).text.split()[0])\n",
    "    except: df['avg_rating'] = ''\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_additional_info(soup, df):\n",
    "    \"\"\"Extract additional product information\"\"\"\n",
    "    try: df['Stock Status'] = soup.find(\"div\", {'id': 'availabilityInsideBuyBox_feature_div'}).text.strip()\n",
    "    except: df['Stock Status'] = ''\n",
    "    \n",
    "    try: df['Seller'] = soup.find(\"a\", {'id': 'sellerProfileTriggerId'}).text.strip()\n",
    "    except: df['Seller'] = ''\n",
    "    \n",
    "    return df\n",
    "\n",
    "def extract_technical_details(soup, df):\n",
    "    \"\"\"Extract technical details from product tables\"\"\"\n",
    "    try:\n",
    "        table = soup.find(\"div\", {\"id\": \"productOverview_feature_div\"}).find(\n",
    "            \"table\", class_=\"a-normal a-spacing-micro\"\n",
    "        )\n",
    "        data = []\n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            row = [td.text for td in tr.find_all(\"td\")]\n",
    "            data.append(row)\n",
    "\n",
    "        table_df = pd.DataFrame(data)\n",
    "        table_df = table_df.applymap(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "        table_df.columns = [\"Attribute_Name\", \"Attribute_Value\"]\n",
    "        table_df = table_df.reset_index(drop=True)\n",
    "        df = pd.concat([df, table_df], axis=1)\n",
    "        col_subset = list(set(df.columns.tolist()) - set([\"Attribute_Name\", \"Attribute_Value\"]))\n",
    "        df[col_subset] = df[col_subset].fillna(method=\"ffill\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting from productOverview_feature_div: {e}\")\n",
    "\n",
    "    try:\n",
    "        table = soup.find(\"table\", {\"id\": \"productDetails_detailBullets_sections1\"})\n",
    "        final_product_spec_df = pd.DataFrame()\n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            product_value = tr.find(\"td\").text.strip()\n",
    "            product_name = tr.find(\"th\").text.strip()\n",
    "            product_spec_df = pd.DataFrame(\n",
    "                {\"Attribute_Name\": [product_name], \"Attribute_Value\": [product_value]}\n",
    "            )\n",
    "            final_product_spec_df = pd.concat([final_product_spec_df, product_spec_df], ignore_index=True)\n",
    "        df = pd.concat([df, final_product_spec_df], ignore_index=True)\n",
    "        cols = df.drop(columns=[\"Attribute_Name\", \"Attribute_Value\"]).columns.tolist()\n",
    "        df[cols] = df[cols].fillna(method=\"ffill\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting from productDetails_detailBullets_sections1: {e}\")\n",
    "\n",
    "    try:\n",
    "        table = soup.find(\"table\", {\"id\": \"productDetails_techSpec_section_1\"})\n",
    "        final_product_spec_df = pd.DataFrame()\n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            product_value = tr.find(\"td\").text.strip()\n",
    "            product_name = tr.find(\"th\").text.strip()\n",
    "            product_spec_df = pd.DataFrame(\n",
    "                {\"Attribute_Name\": [product_name], \"Attribute_Value\": [product_value]}\n",
    "            )\n",
    "            final_product_spec_df = pd.concat([final_product_spec_df, product_spec_df], ignore_index=True)\n",
    "        df = pd.concat([df, final_product_spec_df], ignore_index=True)\n",
    "        cols = df.drop(columns=[\"Attribute_Name\", \"Attribute_Value\"]).columns.tolist()\n",
    "        df[cols] = df[cols].fillna(method=\"ffill\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting from productDetails_techSpec_section_1: {e}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b494e30a-c807-407d-988c-490e5eddada4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>product default order number</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>Product URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0BK1KS6ZD</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.amazon.in/s?rh=n%3A3474656031&amp;fs=true</td>\n",
       "      <td>https://www.amazon.in/dp/B0BK1KS6ZD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0DS2DX5ZP</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.amazon.in/s?rh=n%3A3474656031&amp;fs=true</td>\n",
       "      <td>https://www.amazon.in/dp/B0DS2DX5ZP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0CWVDXYX1</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.amazon.in/s?rh=n%3A3474656031&amp;fs=true</td>\n",
       "      <td>https://www.amazon.in/dp/B0CWVDXYX1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0DQQ4XDBB</td>\n",
       "      <td>6</td>\n",
       "      <td>https://www.amazon.in/s?rh=n%3A3474656031&amp;fs=true</td>\n",
       "      <td>https://www.amazon.in/dp/B0DQQ4XDBB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B09R4RYCJ4</td>\n",
       "      <td>7</td>\n",
       "      <td>https://www.amazon.in/s?rh=n%3A3474656031&amp;fs=true</td>\n",
       "      <td>https://www.amazon.in/dp/B09R4RYCJ4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin product default order number  \\\n",
       "0  B0BK1KS6ZD                            2   \n",
       "1  B0DS2DX5ZP                            3   \n",
       "2  B0CWVDXYX1                            4   \n",
       "3  B0DQQ4XDBB                            6   \n",
       "4  B09R4RYCJ4                            7   \n",
       "\n",
       "                                         listing_url  \\\n",
       "0  https://www.amazon.in/s?rh=n%3A3474656031&fs=true   \n",
       "1  https://www.amazon.in/s?rh=n%3A3474656031&fs=true   \n",
       "2  https://www.amazon.in/s?rh=n%3A3474656031&fs=true   \n",
       "3  https://www.amazon.in/s?rh=n%3A3474656031&fs=true   \n",
       "4  https://www.amazon.in/s?rh=n%3A3474656031&fs=true   \n",
       "\n",
       "                           Product URL  \n",
       "0  https://www.amazon.in/dp/B0BK1KS6ZD  \n",
       "1  https://www.amazon.in/dp/B0DS2DX5ZP  \n",
       "2  https://www.amazon.in/dp/B0CWVDXYX1  \n",
       "3  https://www.amazon.in/dp/B0DQQ4XDBB  \n",
       "4  https://www.amazon.in/dp/B09R4RYCJ4  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_collated_urls = scrape_asin_urls(amazon_listing_url, total_pages)\n",
    "final_collated_urls.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "c213b46c-ef1b-4039-9c4c-2f6587764f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product URL</th>\n",
       "      <th>Title</th>\n",
       "      <th>SKU Product</th>\n",
       "      <th>Scraping Date</th>\n",
       "      <th>Scraping Time</th>\n",
       "      <th>Selling Price</th>\n",
       "      <th>MRP</th>\n",
       "      <th>Discount</th>\n",
       "      <th>no_ratings</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>Stock Status</th>\n",
       "      <th>Seller</th>\n",
       "      <th>Attribute_Name</th>\n",
       "      <th>Attribute_Value</th>\n",
       "      <th>Retailer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.amazon.in/dp/B0BK1KS6ZD</td>\n",
       "      <td>Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...</td>\n",
       "      <td>B0BK1KS6ZD</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>2025-03-01 19:30:11.442388</td>\n",
       "      <td>36990.0</td>\n",
       "      <td>58400.0</td>\n",
       "      <td></td>\n",
       "      <td>3,954 ratings</td>\n",
       "      <td>3.9</td>\n",
       "      <td>In stock</td>\n",
       "      <td>DAWNTECH ELECTRONICS PRIVATE LIMITED</td>\n",
       "      <td>Brand</td>\n",
       "      <td>Daikin</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.amazon.in/dp/B0BK1KS6ZD</td>\n",
       "      <td>Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...</td>\n",
       "      <td>B0BK1KS6ZD</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>2025-03-01 19:30:11.442388</td>\n",
       "      <td>36990.0</td>\n",
       "      <td>58400.0</td>\n",
       "      <td></td>\n",
       "      <td>3,954 ratings</td>\n",
       "      <td>3.9</td>\n",
       "      <td>In stock</td>\n",
       "      <td>DAWNTECH ELECTRONICS PRIVATE LIMITED</td>\n",
       "      <td>Capacity</td>\n",
       "      <td>1.5 Tons</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.amazon.in/dp/B0BK1KS6ZD</td>\n",
       "      <td>Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...</td>\n",
       "      <td>B0BK1KS6ZD</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>2025-03-01 19:30:11.442388</td>\n",
       "      <td>36990.0</td>\n",
       "      <td>58400.0</td>\n",
       "      <td></td>\n",
       "      <td>3,954 ratings</td>\n",
       "      <td>3.9</td>\n",
       "      <td>In stock</td>\n",
       "      <td>DAWNTECH ELECTRONICS PRIVATE LIMITED</td>\n",
       "      <td>Cooling Power</td>\n",
       "      <td>17100 British Thermal Units</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.amazon.in/dp/B0BK1KS6ZD</td>\n",
       "      <td>Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...</td>\n",
       "      <td>B0BK1KS6ZD</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>2025-03-01 19:30:11.442388</td>\n",
       "      <td>36990.0</td>\n",
       "      <td>58400.0</td>\n",
       "      <td></td>\n",
       "      <td>3,954 ratings</td>\n",
       "      <td>3.9</td>\n",
       "      <td>In stock</td>\n",
       "      <td>DAWNTECH ELECTRONICS PRIVATE LIMITED</td>\n",
       "      <td>Special Feature</td>\n",
       "      <td>High Ambient Operation upto 52°C, 3D Airflow, ...</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.amazon.in/dp/B0BK1KS6ZD</td>\n",
       "      <td>Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...</td>\n",
       "      <td>B0BK1KS6ZD</td>\n",
       "      <td>2025-03-01</td>\n",
       "      <td>2025-03-01 19:30:11.442388</td>\n",
       "      <td>36990.0</td>\n",
       "      <td>58400.0</td>\n",
       "      <td></td>\n",
       "      <td>3,954 ratings</td>\n",
       "      <td>3.9</td>\n",
       "      <td>In stock</td>\n",
       "      <td>DAWNTECH ELECTRONICS PRIVATE LIMITED</td>\n",
       "      <td>Product Dimensions</td>\n",
       "      <td>22.9D x 88.5W x 29.8H Centimeters</td>\n",
       "      <td>Amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Product URL  \\\n",
       "0  https://www.amazon.in/dp/B0BK1KS6ZD   \n",
       "1  https://www.amazon.in/dp/B0BK1KS6ZD   \n",
       "2  https://www.amazon.in/dp/B0BK1KS6ZD   \n",
       "3  https://www.amazon.in/dp/B0BK1KS6ZD   \n",
       "4  https://www.amazon.in/dp/B0BK1KS6ZD   \n",
       "\n",
       "                                               Title SKU Product  \\\n",
       "0  Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...  B0BK1KS6ZD   \n",
       "1  Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...  B0BK1KS6ZD   \n",
       "2  Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...  B0BK1KS6ZD   \n",
       "3  Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...  B0BK1KS6ZD   \n",
       "4  Daikin 1.5 Ton 3 Star Inverter Split AC (Coppe...  B0BK1KS6ZD   \n",
       "\n",
       "  Scraping Date              Scraping Time  Selling Price      MRP Discount  \\\n",
       "0    2025-03-01 2025-03-01 19:30:11.442388        36990.0  58400.0            \n",
       "1    2025-03-01 2025-03-01 19:30:11.442388        36990.0  58400.0            \n",
       "2    2025-03-01 2025-03-01 19:30:11.442388        36990.0  58400.0            \n",
       "3    2025-03-01 2025-03-01 19:30:11.442388        36990.0  58400.0            \n",
       "4    2025-03-01 2025-03-01 19:30:11.442388        36990.0  58400.0            \n",
       "\n",
       "      no_ratings  avg_rating Stock Status  \\\n",
       "0  3,954 ratings         3.9     In stock   \n",
       "1  3,954 ratings         3.9     In stock   \n",
       "2  3,954 ratings         3.9     In stock   \n",
       "3  3,954 ratings         3.9     In stock   \n",
       "4  3,954 ratings         3.9     In stock   \n",
       "\n",
       "                                 Seller      Attribute_Name  \\\n",
       "0  DAWNTECH ELECTRONICS PRIVATE LIMITED               Brand   \n",
       "1  DAWNTECH ELECTRONICS PRIVATE LIMITED            Capacity   \n",
       "2  DAWNTECH ELECTRONICS PRIVATE LIMITED       Cooling Power   \n",
       "3  DAWNTECH ELECTRONICS PRIVATE LIMITED     Special Feature   \n",
       "4  DAWNTECH ELECTRONICS PRIVATE LIMITED  Product Dimensions   \n",
       "\n",
       "                                     Attribute_Value Retailer  \n",
       "0                                             Daikin   Amazon  \n",
       "1                                           1.5 Tons   Amazon  \n",
       "2                        17100 British Thermal Units   Amazon  \n",
       "3  High Ambient Operation upto 52°C, 3D Airflow, ...   Amazon  \n",
       "4                  22.9D x 88.5W x 29.8H Centimeters   Amazon  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Product Detail Scraping\n",
    "final_scrapped_df = scrape_product_details(final_collated_urls)\n",
    "final_scrapped_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
